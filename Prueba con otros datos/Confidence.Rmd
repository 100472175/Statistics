---
title: "**Confidence intervals**"
author: "Eduardo Alarcón & Alfonso Pineda"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# 2 Example 1: Web-page accessing times

We want to construct the confidence intervals for the mean, $\mu$, and for the variance, $\sigma^2$, of the distribution of the accessing times to a web page of UC3M from a specific computer at home as well as from a computer in the UC3M campus. The confidence intervals will be constructed by using 55 observations (in seconds). Each observation consists of two accessing times, one measured on a home computer and one on a computer belonging to the university campus (file `TiempoaccesoWeb.xlsx`)

First we read and view the data file. The figure shows the first five observations of this datafile. 

```{r}
library(readxl)
SpotifySongs <- read_excel("songstats.xlsx")
```

# 2.1. Univariate analysis of data

Before doing any kind of analysis it is useful to first describe the variables of interest. We start with the access times of the computer at home (variable `energy`). The numerical and graphical analysis can be performed by

```{r message=FALSE, warning=FALSE}
suppressWarnings(library(summarytools))
descr(SpotifySongs$energy)
hist(energy, breaks = seq(100, 1000, 50), 
     probability = TRUE, # histogram has a total area = 1
     xlab = "Energy") 
curve(dnorm(x, mean(energy), sd(energy)), 
      col="blue", lwd=2, add=TRUE, yaxt="n")
```

We can notice in the figure that the variable `energy` has a Normal-liked distribution: it is quite symmetric and bell-shaped. The hypothesis of normality is important to compute the confidence intervals. For example to construct a confidence interval for the variance it is *mandatory* to assume the normality since only in that case we know that the estimator is distributed as a Chi-squared distribution.

The summary statistics include measures of central tendency, measures of variability and measures of shape, we can notice that the values of the Skewness and the Kurtosis are quite small confirming the fact that the histogram looks like a Normal distribution.

Among these values, the sample mean and variance are the "point" estimations of the population mean and variance. That is, we have that in this sample, the "point" estimation of the parameters of interest are $\widehat{\mu} = 660.92$ and $\widehat{\sigma}^2 = 185.68^2$.

*Our objective is to make an “interval” estimation of these parameters*.

## 2.2 Analysis of the Normality of the variable

We perform a goodness-of-fit test to check if the variable can be assumed normal. For simplicity, we will use the normality tests provided by package `nortest`

```{r}
library(nortest)
ad.test(energy)
cvm.test(energy)
lillie.test(energy)
pearson.test(energy)
sf.test(energy)
```


# 2.3 Confidence intervals

To obtain the confidence intervals for the mean, $\mu$, and the variance, $\sigma^2$, we evaluate the following expressions:

* Confidence interval for $\mu$ with known variance:
$\bar{x} \mp z_{\alpha/2} \frac{\sigma}{\sqrt{n}},$
where $n$ is the sample size, $\sigma$ is the known standard deviation, $z_{\alpha/2}$ is the ($\alpha/2$)-percentil of the standard normal distribution (`qnorm(alpha/2)` in \textsf{R}) and $\bar{x}$ is the sample mean (`mean(x)` in \textsf{R}).

 In the example

```{r}
alpha = 0.05
n = length(energy)
xmean = mean(energy)
xsd = sd(energy)
z = qnorm(alpha/2, lower.tail = FALSE)
LowerLimit = xmean - z * xsd / sqrt(n)
UpperLimit = xmean + z * xsd / sqrt(n)
LowerLimit
UpperLimit
```
 where we assume that $\sigma$ is known and equals to `sd(TiempoAccesoWeb$Ordenador_Casa)`. 
 $\mu\in( 632.7611, 689.0832)$
 
\vspace{0.25cm}
The above confidence intervals can be obtained as output of some functions implementing hyphotesis testing:
* Confidence interval for $\mu$ with known variance using `z.test`:

```{r message=FALSE, warning=FALSE}
suppressWarnings(library(BSDA))
z.test(energy, sigma.x = xsd)$conf.int
```


# 3. Example 2: Loop execution time

We consider the file `TiempoBucle.xlsx` that contains the durations in seconds of the executions of a Matlab program under different conditions. For each set of conditions we repeated the measurements of the executions 200 times. We want to construct the confidence interval for the population mean and variance of the execution times under the conditions defined for the variable `Estado1`.

## 3.1 Univariate analysis of data

We analyze the execution times contained in the variable `Estado1`. First we read and view the data file. The figure shows the first five observations of this datafile. 


```{r, echo = FALSE}
library(readxl)
TiempoBucle <- read_excel("TiempoBucle.xlsx")
```


The graphical and numerical analysis is obtained by

```{r message=FALSE, warning=FALSE}
suppressWarnings(library(summarytools))
descr(TiempoBucle$Estado1, na.rm = TRUE)
hist(TiempoBucle$Estado1, 
     probability = TRUE, # histogram has a total area = 1
     xlab = "Time of loop") 
curve(dnorm(x, mean(TiempoBucle$Estado1, na.rm = T), sd(TiempoBucle$Estado1, na.rm = T)), 
      col="blue", lwd=2, add=TRUE, yaxt="n")
```

We can observe that the distribution is concentrated around 0,18 seconds and it shows a strong positive symmetry. The variable looks more peaked than a bell, and therefore we conclude that it does not look Normal.

Among the statistics’ values, the sample mean and variance are the “point” estimations of the population mean and variance. That is, we have that in this sample, the “point” estimation of the parameters of interest are $\widehat{\mu} = 0.18$ and $\widehat{\sigma}^2 = 0.01^2$.


Our objective is to make an “interval” estimation of these parameters.

# 3.2 Analysis of the Normality of the variable

To construct the confidence intervals we need to check if the variable of interest is normally distributed or not (why?). The histogram above did not look like a normal density function. In addition the values of Skewness and Kurtosis are high that denotes a positive asymmetry and a shape more peaked than a Normal one. The following lines perfoms some normality goodness-of-fit tests:

```{r}
library(nortest)
ad.test(TiempoBucle$Estado1)
cvm.test(TiempoBucle$Estado1)
lillie.test(TiempoBucle$Estado1)
pearson.test(TiempoBucle$Estado1)
sf.test(TiempoBucle$Estado1)
```

The picture above shows that the fitting is indeed low precise. In addition from previous tests we see that the p-values are practically equal to zero, therefore we have to reject our null hypothesis of normality for the variable `Estado1`.

Since the sample size is large by the Central Limit Theorem we can assume that still the estimator for the population mean (the sample mean) has a normal distribution. Therefore even if the variable `Estado1` is not normal we can still construct a confidence interval for the mean, **but we CANNOT construct a confidence interval for its standard deviation or its variance**.

\newpage

# 3.3 Confidence Intervals

To get the confidence interval for the mean, $\mu$, we will use the output of functions `z.test` and `t.test`

```{r}
library(BSDA)
z.test(TiempoBucle$Estado1, sigma.x = sd(TiempoBucle$Estado1, na.rm = T))$conf.int
t.test(TiempoBucle$Estado1)$conf.int
```

It should be noted that `z.test` does not work when there are `NA`. So, we should remove the NA using the function `na.exclude`

```{r}
library(BSDA)
z.test(na.exclude(TiempoBucle$Estado1), sigma.x = sd(TiempoBucle$Estado1, na.rm = T))$conf.int
t.test(TiempoBucle$Estado1)$conf.int
```

Both intervals are very similar since the sample size is 200, then  $z_\alpha \approx t_{n-1, \alpha}$. 


Therefore the mean execution time of the Matlab program under the conditions used for the variable `Estado1` is a value contained in the interval [0.1799897, 0.1814403] seconds with a confidence level of 95%. Since the distribution of the random variable is not Normal, the confidence interval for the variance is not reliable and therefore we did not calculate it.



